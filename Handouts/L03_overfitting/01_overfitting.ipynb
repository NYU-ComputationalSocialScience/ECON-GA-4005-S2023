{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6cdd6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overfitting\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- Linear Algebra\n",
    "- Linear Models\n",
    "\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand polynomial regression\n",
    "- Understand and be able to diagnose overfitting\n",
    "- Understand and be able to apply K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fd8b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542dbb7c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Warmup: Polynomial Regression\n",
    "\n",
    "- Recall that a **linear model** is a model that is linear in *parameters*\n",
    "- This may seem limiting, but can be quite expressive\n",
    "- Two main dimensions of flexibility are:\n",
    "    1. Link functions and residual families: GLM (last time)\n",
    "    2. Feature engineering: transforming observed data $x \\in \\mathbb{X}$ (today+)\n",
    "- Today we'll explore how the linear model can be *too flexible*\n",
    "- We'll warm up with a contrived example of **polynomial regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bf34f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Notation\n",
    "\n",
    "Define the convenience function *polynomial_features* that implements the polynomial feature mapping/transformation $\\boldsymbol{\\phi}(\\cdot)$ for a $D$-degree polynomial\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\phi_D(x) & \\triangleq\n",
    "    \\begin{bmatrix}\n",
    "        1       \\\\\n",
    "        x \\\\\n",
    "        x^2 \\\\ \n",
    "        \\vdots \\\\\n",
    "        x^{D-1} \\\\\n",
    "        x^D\n",
    "    \\end{bmatrix}    \n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d600a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "For a vector $\\mathbf{x} \\in \\mathbb{R}^N$ as input argument, it constructs and returns the matrix\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\Phi_D & \\triangleq\n",
    "    \\begin{bmatrix}\n",
    "        \\phi_D^T(x_1) \\\\\n",
    "        \\phi_D^T(x_2) \\\\\n",
    "        \\vdots  \\\\\n",
    "        \\phi_D^T(x_N) \\\\ \n",
    "    \\end{bmatrix} =    \n",
    "    \\begin{bmatrix}\n",
    "        1 & x_1 & x_1^2 & \\cdots & x_1^{D-1} & x_1^D  \\\\\n",
    "        1 & x_2 & x_2^2 & \\cdots & x_2^{D-1} & x_2^D  \\\\\n",
    "        \\vdots  \\\\\n",
    "        1 & x_N & x_N^2 & \\cdots & x_N^{D-1} & x_N^D\n",
    "    \\end{bmatrix} \\in \\mathbb{R}^{N \\times (D+1)}   \n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76cebca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### `sklearn.preprocessing.PolynomialFeatures`\n",
    "\n",
    "The `sklearn.preprocessing` module contains many tools for preprocessing data\n",
    "\n",
    "One of these tools is `PolynomialFeatures`\n",
    "\n",
    "We'll use `PolynomialFeatures` to implement our $\\Phi$ operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d63d6b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "quad = preprocessing.PolynomialFeatures(degree=2)\n",
    "cubic = preprocessing.PolynomialFeatures(degree=3)\n",
    "\n",
    "x = np.arange(1, 8)\n",
    "\n",
    "cubic.fit_transform(x[:, None])  # make x (N, 1) b/c sklearn expects matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f3c31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Experiment Setup\n",
    "\n",
    "We will use \n",
    "\n",
    "To test out polynomial regression, we'll do an experiment:\n",
    "\n",
    "1. Define a cubic polynomial with known coefficients $\\theta_{\\text{true}}$: $y = \\theta_{\\text{true}}^T \\phi_3(x)$\n",
    "2. Draw $x_i \\stackrel{\\text{iid}}{\\sim} U[0, 3]$ for $i =1, \\cdots, N$\n",
    "3. Draw noise $\\epsilon_i \\stackrel{\\text{iid}}{\\sim} N(0, 0.05)$ for $i =1, \\cdots, N$\n",
    "4. Generate noisy data using from the polynomial: $y_i = \\theta_{\\text{true}}^T\\phi_3(x_i) + \\epsilon_i$\n",
    "\n",
    "The observations $y_i$ will be noisy samples from our assumed data generating process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b15ce9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Define Polynomial\n",
    "\n",
    "We will define a cubic polynomial, which we'll call the *true model*:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    & f(x|\\theta_{\\mathrm{true}}) = \\frac{A}{3} x^3 - \\frac{A(a+b)}{2} x^2 + A a b x = \\theta_{\\mathrm{true}}^T \\phi_3(x)\n",
    "\\end{aligned}$$\n",
    "\n",
    "where the polynomial coefficients $\\theta_{\\mathrm{true}}$ are given as\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\theta_{\\mathrm{true}} & \\triangleq\n",
    "    \\begin{bmatrix} 0 \\\\ A a b \\\\-\\frac{A}{2}(a+b) \\\\ \\frac{A}{3} \\end{bmatrix}\n",
    "\\end{aligned}$$\n",
    "\n",
    "and the polynomial feature map $\\phi_3(\\cdot)$ is given as\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\phi_3(x) & \\triangleq \\begin{bmatrix} 1 \\\\ x \\\\ x^2 \\\\ x^3 \\end{bmatrix}    \n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf6146",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## True model (polynomial) specification\n",
    "\n",
    "# The parameters that follow influence the shape of the polynomial (feel free to change)\n",
    "a = 1.0    # First stationary point of polynomial\n",
    "b = 1.5    # Second stationary point of polynomial\n",
    "A = 2.0    # Scaling factor\n",
    "\n",
    "# Polynomial coefficients (do not change)\n",
    "theta_true = np.zeros(4)\n",
    "theta_true[1] = A * a * b\n",
    "theta_true[2] = - A * (a + b) / 2.0\n",
    "theta_true[3] = A / 3.0\n",
    "\n",
    "theta_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240b030",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Draw $x_i$ and $\\epsilon_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # for reproducible results\n",
    "\n",
    "N = 100\n",
    "xmin = 0\n",
    "xmax = 3\n",
    "x = xmin + (xmax - xmin) * np.random.rand(N)\n",
    "\n",
    "sigma = 0.05\n",
    "epsilon = np.random.randn(N) * np.sqrt(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644dca1a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Generate $y_i$ using $\\theta_{\\text{true}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the target values\n",
    "Phi = cubic.fit_transform(x[:, None])\n",
    "y = Phi @ theta_true + epsilon\n",
    "\n",
    "# also construct data for plotting later\n",
    "x_plot = np.linspace(xmin, xmax, 40)\n",
    "y_true_plot = cubic.fit_transform(x_plot[:, None]) @ theta_true\n",
    "\n",
    "plt.plot(x_plot, y_true_plot);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6beb3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Data Partitioning\n",
    "\n",
    "The available data will be partitioned into a *training* set and *test* set (i.e. samples not used for training/fitting)\n",
    "\n",
    "In particular, the test set will be used to obtain an honest estimate of how good the model performs on previously unseen samples (i.e. samples other than ones used for training)\n",
    "\n",
    "We'll use `sklearn.model_selection.train_test_split` for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Partition data into training and test set\n",
    "# Number of training samples (feel free to change)\n",
    "N_train = 10\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    x, y, train_size=N_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6ff62",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Model Training/Fitting\n",
    "\n",
    "Let's now run a degree-3 polynomial regression to see how well we can fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332aa03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics\n",
    "\n",
    "# construct feature matrix\n",
    "X_train = cubic.fit_transform(x_train[:, None])\n",
    "\n",
    "# choose and fit model\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# compute predictions on training data\n",
    "y_hat_train = model.predict(X_train)\n",
    "\n",
    "# evaluate mse\n",
    "mse_train = metrics.mean_squared_error(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6703c51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_plot, y_true_plot)\n",
    "ax.plot(x_train, y_hat_train, \"r.\", ms=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574cb6c",
   "metadata": {},
   "source": [
    "Overall the fit looks pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af3fd2c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Let's check the coefficients and the mse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4161d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a07e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9fe123",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Test set prediction\n",
    "\n",
    "Now let's evaluate our fit model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46230c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cubic.transform(x_test[:, None])\n",
    "y_hat_test = model.predict(X_test)\n",
    "mse_test = metrics.mean_squared_error(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79745e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The optimal coefficients are:\\n')\n",
    "print(model.coef_)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('The (minimum) MSE of the fitted model as computed on the training set is\\nMSE_train={:.3f}\\n'.format(mse_train))\n",
    "print('The MSE of the fitted model as computed on the test set is\\nMSE_test={:.3f}\\n'.format(mse_test))\n",
    "print('The noise variance of the true model is\\nsigmaSquared_e={:.3f}\\n'.format(sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ce4d2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ce1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize figure to make it bigger\n",
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "\n",
    "X_plot = cubic.transform(x_plot[:, None])\n",
    "y_hat_plot_fitted = model.predict(X_plot)\n",
    "polydegree = 3\n",
    "\n",
    "ax.plot(x_plot, y_hat_plot_fitted, 'r', lw=3, label=\"Fitted model\")\n",
    "ax.plot(x_plot, y_true_plot, 'g', lw=3, label=\"True model\")\n",
    "ax.scatter(x_test, y_test, s=100, facecolors='none', edgecolors='b', label=\"Test data\")\n",
    "ax.scatter(x_train, y_train, s=100, facecolors='r', edgecolors='k', label=\"train data\")\n",
    "\n",
    "# Annotate graph\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title((\n",
    "    \"Fitted vs. True Model Responses: \"\n",
    "    f\"Ntrain={N_train:d} deg={polydegree:d} MSEtrain={mse_train:.3f}, \"\n",
    "    f\"MSEtest={mse_test:.3f}, NoiseVar={sigma:.3f}\"\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238cdabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e730bf0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Notice that the largest training sample $x$ is just less than 2.0\n",
    "\n",
    "The model fits best in the region closest to the training data\n",
    "\n",
    "As we evaluate the model at x > 2.5 the fit deteriorates and the residuals increase\n",
    "\n",
    "This is known as poor *generalization*\n",
    "\n",
    "Generalization refers to the ability for a model to produce accurate predictions on unseen data. This is the **main goal** of supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d73ca9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Interactive Example\n",
    "\n",
    "Above we saw how we could assume a data generating process where $y$ was related to $x$ by a cubic polynomial\n",
    "\n",
    "Unsurprisingly, we found that if we fit noisy observations $(y_i, x_i)$ using a cubic polynomial we had a good fit in the region of the training data\n",
    "\n",
    "What if we were to use a degree 4 or degree 5 polynomial? Would the fit improve? How about generalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08903f",
   "metadata": {},
   "source": [
    "We will use jupyter widgets to construct an interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def polyreg_demo(degree=3, n_train=10):\n",
    "    # define model\n",
    "    model = pipeline.make_pipeline(\n",
    "        preprocessing.PolynomialFeatures(degree=degree),\n",
    "        linear_model.LinearRegression()\n",
    "    )\n",
    "    \n",
    "    X = x[:, None]  # convert to 2d\n",
    "    test_size = X.shape[0] - n_train\n",
    "    split = model_selection.train_test_split(X, y, train_size=n_train, test_size=test_size, random_state=12)\n",
    "    X_train, X_test, y_train, y_test = split\n",
    "   \n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    yhat = model.predict(x_plot[:, None])\n",
    "    \n",
    "    # compute metrics\n",
    "    mse_train = metrics.mean_squared_error(y_train, model.predict(X_train))\n",
    "    mse_test = metrics.mean_squared_error(y_test, model.predict(X_test))\n",
    "\n",
    "    # make the plot\n",
    "    fig, ax = plt.subplots(figsize=(11, 8))\n",
    "    ax.plot(x_plot, yhat, \"k-\", lw=3, label=\"Fitted Model\")\n",
    "    ax.scatter(X_test.flatten(), y_test, color=\"b\", s=60, alpha=0.5, label=\"Test Data\")\n",
    "    ax.scatter(X_train.flatten(), y_train, color=\"r\", s=80, alpha=0.7, label=\"Training Data\") \n",
    "    ax.set_ylim((-20, 20))\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_title((\n",
    "        \"Fitted vs. True Model Responses: \"\n",
    "        f\"Ntrain={n_train:d} deg={degree:d} MSEtrain={mse_train:.3f}, \"\n",
    "        f\"MSEtest={mse_test:.3f}, NoiseVar={sigma:.3f}\"\n",
    "    ))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "widgets.interactive(polyreg_demo, degree=(1, 10, 1), n_train=(5, 95, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a47b4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Things to try:\n",
    "\n",
    "- Try leaving degree at 3, but moving n_train to 2 or 1. What happens?\n",
    "- Now set n_train to 10 and try moving degree from 3 towards 10. What happens to MSEtrain as degree increases? what about MSEtest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764a4f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Overfitting\n",
    "\n",
    "- As shown above, when the number of training samples is too low relative to the model complexity the model will often exhibit very good training properties (i.e. a low `MSEtrain`), but very poor generalization (i.e. a high `MSEtest`)\n",
    "- This is called **overfitting** and is one of the most common problems machine learning practitioners have to grapple with\n",
    "- An overfit model is dangerous because it can make the modeler feel confident due to good training metrics, but then give very wrong predictions in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955dd2c1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Diagnosing Overfitting\n",
    "\n",
    "- It is important to check for and diagnose overfitting\n",
    "- Common strategy:\n",
    "    1. Split dataset into training and testing subsets\n",
    "    2. Train data only on training subset\n",
    "    3. Evaluate metrics on both training and testing subsets\n",
    "    4. Compare MSE train to MSE test\n",
    "- This is what we did above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc44f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Strategies for overcoming Overfitting\n",
    "\n",
    "- Once overfitting has been diagnosed, there are three standard counterattacks:\n",
    "\n",
    "1. Use more training data\n",
    "2. Use a less complex model (perhaps use fewer features)\n",
    "3. Use a regularization approach (stay tuned!)\n",
    "\n",
    "- Often (1) is not possible or feasible\n",
    "- Sometimes relationships are highly non-linear and complex, ruling out (2)\n",
    "- (3) is the most commonly used approach for complex models and big data (e.g. modern deep networks)\n",
    "- Implementing (2) or (3) surfaces need to be able to select from a set of candidate models..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e4335",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Model Selection\n",
    "\n",
    "-   Select from a set of models with varying flexibility\n",
    "-   **Goal**: Choose a model that has the best generalization\n",
    "    properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd198c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "-   Example: polynomial regression\n",
    "    -   Varying number of features, controlled by degree $D$ of\n",
    "        polynomial\n",
    "    -   The number $D$ indexes a family of regression models and\n",
    "        controls flexibility\n",
    "    -   Optimal $D$ cannot be determined based solely on training set\n",
    "        (beware of overfitting!)\n",
    "    -   Parameters like $D$ are called **hyper parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31772a8c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Model Selection continued ...\n",
    "\n",
    "**Main point**\n",
    "\n",
    "-   Model selection cannot be solely based on the training set\n",
    "-   Training MSE informs us about model fit, but not necessarily about\n",
    "    the model's generalization performance (not trustworthy)\n",
    "-   A (more) honest loss estimate needs to be employed\n",
    "    -   We used a hold-out set for this purpose (more trustworthy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564d530",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Validation Procedure**\n",
    "\n",
    "-   An approach to model selection: out of a pool of candidate models,\n",
    "    guess which one may exhibit the best generalization (let's decide to\n",
    "    call it the **champion model**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ee816",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Validation Procedures\n",
    "\n",
    "-   There are many, we'll only cover a few\n",
    "- The pattern described above is called the **Hold out method**\n",
    "- We'll repeat here for practice:\n",
    "    1.   Partition available data into training (typically, larger set)\n",
    "         and (typically, smaller set) hold-out set, called the\n",
    "         **validation set**.\n",
    "    2.   Fit models on training set\n",
    "    3.   Select model with smallest average loss on hold-out set\n",
    "-   Considerations\n",
    "    -   Large training set $\\Longrightarrow$ better fitting models\n",
    "    -   The larger the validation set, the better quality of the\n",
    "        generalization estimate (e.g. $\\text{MSE}_{\\text{val}}$)\n",
    "    -   Assumes there are plenty of data for both sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bab6c8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Aside: train, test, validate\n",
    "\n",
    "- The process above labeled a hold out set the validation set\n",
    "- This is distinct from the testing dataset we used in our polynomial regression example\n",
    "- In a full setup, you may split the dataset into three partitions:\n",
    "    1. Training: largest, used for training model\n",
    "    2. Validation: medium size, used for tuning hyperparameters of each model\n",
    "    3. Testing: smallest, used to compare generalization properties of candidate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1acfbea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### K-fold Cross Validation\n",
    "\n",
    "-   Partition available data into $K$ equally-sized subsets\n",
    "    (**folds**)\n",
    "-   For $k=1$ to $K$\n",
    "    -   Pick a fold to play the role of the validation set\n",
    "    -   Use the remaining $K-1$ folds for training the models\n",
    "    -   Compute the average loss on the validation set/fold\n",
    "-   Use the sample average of the\n",
    "    $\\left\\{\\text{MSE}_{\\text{val}}^k \\right\\}_{k=1}^K$ to guess the\n",
    "    best generalizing model (champion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11b911",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### K-fold... vizualized\n",
    "\n",
    "![Simple Linear Regression](https://css-materials.s3.amazonaws.com/ML/overfitting/kfold_crossval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e0e62",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### K-fold CV\n",
    "\n",
    "-   Considerations for K-fold CV\n",
    "    -   For fixed number of available data $N$\n",
    "        -   large $K$ $\\Longrightarrow$ large training sets and small\n",
    "            validation sets $\\Longrightarrow$ worse quality of\n",
    "            generalization performance estimate\n",
    "    -   Used when data are deemed \"not enough\" to employ hold-out method\n",
    "    -   Often, people use K=10 (although completely arbitrary)\n",
    "-   Leave ont out cross validation (LOOCV)\n",
    "    -   K-fold CV to the extreme: $K = N$\n",
    "    -   Considerations\n",
    "        -   Used when available data are \"too few\"\n",
    "        -   Training sets almost identical from fold to fold\n",
    "            $\\Longrightarrow$ trained models typically differ by very\n",
    "            little from fold to fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621e55af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Example: Apply to Polynomial Regression\n",
    "\n",
    "- Let's work through an example of K-fold cross validation using our polynomial regression laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dafe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyreg_model(degree):\n",
    "    return pipeline.make_pipeline(\n",
    "        preprocessing.PolynomialFeatures(degree=degree),\n",
    "        linear_model.LinearRegression(fit_intercept=False)\n",
    "    )\n",
    "\n",
    "\n",
    "def fit_polyreg_return_mse(train_x, train_y, test_x, test_y, degree):\n",
    "    model = polyreg_model(degree)\n",
    "    model.fit(train_x, train_y)\n",
    "    test_yhat = model.predict(test_x)\n",
    "    return metrics.mean_squared_error(test_y, test_yhat)\n",
    "\n",
    "\n",
    "def do_k_fold_validation_polyreg(k, x, y, degrees):\n",
    "    model_scores = {d: 0.0 for d in degrees}\n",
    "    \n",
    "    kf = model_selection.KFold(n_splits=k, shuffle=True)\n",
    "    for train_index, test_index in kf.split(x):  # repeated k times\n",
    "        # split data\n",
    "        x_train = x[train_index, None]\n",
    "        y_train = y[train_index]\n",
    "        \n",
    "        x_test = x[test_index, None]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        for d in degrees:\n",
    "            score = fit_polyreg_return_mse(x_train, y_train, x_test, y_test, degree=d)\n",
    "            model_scores[d] += score\n",
    "    \n",
    "    # compute average of model scores\n",
    "    return {d: mse / k for d, mse in model_scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2d9e0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_k_fold_validation_polyreg(10, x, y, range(1, 31))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31533f72",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Using Sklearn\n",
    "\n",
    "We can actually simplify our code quite a bit by letting Sklearn handle the details for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accec2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_crossval_via_sklearn(k, x, y, degrees):\n",
    "    scores = {}\n",
    "    for d in degrees:\n",
    "        model = polyreg_model(d)\n",
    "        mses = model_selection.cross_val_score(\n",
    "            model, \n",
    "            x[:, None], \n",
    "            y,  \n",
    "            scoring='neg_mean_squared_error', \n",
    "            cv=k\n",
    "        )\n",
    "        scores[d] = -mses.mean()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99051e79",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_fold_crossval_via_sklearn(10, x, y, range(1, 31))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516058e5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### LOOCV with Linear Regression\n",
    "\n",
    "An amazing thing...\n",
    "\n",
    "-   The LOOCV estimate for linear regression has a closed form based on the diagonal elements of the hat matrix $\\mathbf{H}$.\n",
    "$$\\begin{aligned}\n",
    "    \\text{MSE}_{\\text{loocv}} &= \\frac{1}{N} \\sum_{n=1}^{N} \\frac{\\hat{e}_n^2}{(1 - h_{n,n})^2} = \\frac{1}{N}\\hat{\\mathbf{e}}^{*T} \\left(\\mathbf{I}_N - \\mathbf{H}_{\\text{diag}} \\right)^{-2} \\hat{\\mathbf{e}}^* \\\\\n",
    "    & \\text{ } \\\\\n",
    "    \\mathbf{H} &\\triangleq \\mathbf{X} \\mathbf{X}^{\\dagger} \\\\\n",
    "    \\mathbf{H}_{\\text{diag}} &\\triangleq \\text{diagonal elements of } \\mathbf{H} = \\begin{bmatrix}\n",
    "        h_{1,1} & 0 & \\cdots \\\\\n",
    "        0 & h_{2,2} & \\cdots \\\\\n",
    "        \\vdots & \\vdots & \\ddots\n",
    "    \\end{bmatrix}\n",
    "\\end{aligned}$$\n",
    "-   In the literature it is called the **P**redicted **R**esidual **E**rror **S**um of**S**quares (PRESS) statistic\n",
    "-   In essence it is a weighted form of the training MSE\n",
    "- NOTE: can be computed by fitting *1* model, not *N*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44b05a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Example\n",
    "\n",
    "Let's test out this finding with our polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_model = polyreg_model(degree=2)\n",
    "quad_model.fit(x[:, None], y)\n",
    "eps_star = quad_model.predict(x[:, None]) - y\n",
    "\n",
    "X = quad.fit_transform(x[:, None])\n",
    "H = X @ np.linalg.pinv(X)\n",
    "hh = np.diagonal(H)\n",
    "mse_loocv = np.mean((eps_star /(1-hh))**2)\n",
    "mse_loocv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_k_fold_validation_polyreg(len(x), x, y, [2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9b8795",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Comments about Model Selection\n",
    "\n",
    "-   Hold-out method more reliable than K-fold CV or LOOCV\n",
    "    -   It will provide most honest estimate of generalization\n",
    "        performance\n",
    "    -   However, hold-out data is not used for training\\...\n",
    "    -   It is most commonly used when there is ample data\n",
    "-   In general, the best validation procedure depends on\n",
    "    1.  The context of the ML task\n",
    "    2.  The size of available data set\n",
    "    3.  Efficiency/feasibility concerns\n",
    "    4.  The choice of hyper-parameters (such as the number of folds $K$\n",
    "        in K-fold CV)\n",
    "-   This is a **difficult problem** that is being actively researched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f108e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "formats": "ipynb,md,py:percent"
  },
  "kernelspec": {
   "display_name": "css",
   "language": "python",
   "name": "css"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
